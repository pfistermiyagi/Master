{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting UFC Fights With Supervised Learning\n",
    "Adam Pfister - Oregon, USA - November 7, 2019  \n",
    "\n",
    "This project focuses on UFC fight prediction using supervised learning models. The data comes from Kaggle (https://www.kaggle.com/rajeevw/ufcdata). A big thank you to the originator of this data, Rajeev Warrier. It is detailed and well put-together with zero missing data.  \n",
    "\n",
    "Below in quotes is info about the two original datasets directly from its Kaggle page:  \n",
    " \n",
    "\" This is a list of every UFC fight in the history of the organisation. Every row contains information about both fighters, fight details and the winner. The data was scraped from ufcstats website. After fightmetric ceased to exist, this came into picture. I saw that there was a lot of information on the website about every fight and every event and there were no existing ways of capturing all this. I used beautifulsoup to scrape the data and pandas to process it. It was a long and arduous process, please forgive any mistakes. I have provided the raw files incase anybody wants to process it differently. This is my first time creating a dataset, any suggestions and corrections are welcome! Incase anyone wants to check out the work, I have all uploaded all the code files, including the scraping module here.  \n",
    "\n",
    "Each row is a compilation of both fighter stats. Fighters are represented by 'red' and 'blue' (for red and blue corner). So for instance, red fighter has the complied average stats of all the fights except the current one. The stats include damage done by the red fighter on the opponent and the damage done by the opponent on the fighter (represented by 'opp' in the columns) in all the fights this particular red fighter has had, except this one as it has not occured yet (in the data). Same information exists for blue fighter. The target variable is 'Winner' which is the only column that tells you what happened. Here are some column definitions. \"\n",
    "\n",
    "\n",
    "### Overview  \n",
    "1. __Explore Original Datasets__  \n",
    "    > 1. Size and shape\n",
    "    > 2. Sample view\n",
    "    > 3. Missing data  \n",
    "2. __Create New Variables and Clean Data__  \n",
    "    > 1. Combine and create new variables\n",
    "    > 2. Parse date/time\n",
    "    > 3. Create dummy binary columns for 'Winner' category\n",
    "    > 4. (Optional) trim dataset to include only 2011-2019 and four men's weight classes: featherweight, lightweight, welterweight, middleweight \n",
    "    > 5. Create subset dataframe of key variables  \n",
    "3. __Exploratory Data Analysis__  \n",
    "    > 1. Basic statistics\n",
    "    > 2. Bar plot  \n",
    "        - total wins (red vs blue)\n",
    "    > 3. Count plot  \n",
    "        - weight classes\n",
    "    > 4. Distribution plots  \n",
    "        - total fights (red vs blue)\n",
    "        - wins (red vs blue)\n",
    "        - age (red vs blue)  \n",
    "    > 5. Pair plots    \n",
    "        - offense and defense (red vs blue) compared to red wins  \n",
    "        - win % and finish % (red vs blue) compared to red wins  \n",
    "    > 6. Correlation matrix of key variables\n",
    "4. __Supervised Learning__  \n",
    "    > 1. Define and preprocess data\n",
    "    > 2. Support vector machine\n",
    "    > 3. Naive Bayes\n",
    "    > 4. Logistic regression\n",
    "    > 5. Decision tree/random forest  \n",
    "5. __Summary and Conclusion__\n",
    "6. __Acknowledgments__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import original kaggle datasets\n",
    "df_clean = pd.read_csv(r'C:\\Users\\AP\\Desktop\\ufc-fight-stats-clean.csv')\n",
    "df_raw = pd.read_csv(r'C:\\Users\\AP\\Desktop\\ufc-fight-stats.csv')\n",
    "\n",
    "# change all columns to lower case for ease and consistency of typing\n",
    "df_clean.columns = map(str.lower, df_clean.columns)\n",
    "df_raw.columns = map(str.lower, df_raw.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "### Explore Original Datasets\n",
    "\n",
    "#### Pre-processed Dataset  \n",
    "\n",
    "1. Size and shape\n",
    "2. Sample view\n",
    "3. Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# basic size and shape of preprocessed dataset\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- The dataset contains 160 columns and approximately 3600 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample view of dataset\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantify missing data\n",
    "total_missing = df_clean.isnull().sum().sort_values(ascending=False)\n",
    "percent_missing = (df_clean.isnull().sum()/df_clean.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total_missing, percent_missing], axis=1, keys=['Count', 'Percent'])\n",
    "\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Dataset   \n",
    "\n",
    "1. Size and shape\n",
    "2. Sample view\n",
    "3. Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic size and shape of dataset\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- The raw dataset has 145 columns and approximately 5100 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample view of dataset\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantify missing data\n",
    "total_missing = df_raw.isnull().sum().sort_values(ascending=True)\n",
    "percent_missing = (df_raw.isnull().sum()/df_raw.isnull().count()).sort_values(ascending=True)\n",
    "missing_data = pd.concat([total_missing, percent_missing], axis=1, keys=['Count', 'Percent'])\n",
    "\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- There are several differences between the two datasets. The raw set contains variables not found in the preprocessed version. This includes each fighter's name, who refereed the bout, and the date and location of the fight. The preprocessed version drops these variables and adds some more detailed fight metrics.  \n",
    "  \n",
    "- We need to combine some categories from each dataset. First, we will parse the date/time column in the raw set and add it to the preprocessed set.  \n",
    "\n",
    "- No missing data! Thank you to the originator of this data, Rajeev Warrier.  \n",
    "\n",
    "- Let's clean the data and create/combine new variables based on my intuitions from years of training and watching mixed martial arts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "\n",
    "# Create New Variables and Clean Data  \n",
    "\n",
    "1. Combine and create new variables\n",
    "2. Parse date/time\n",
    "3. Create dummy binary columns for 'Winner' category\n",
    "4. (Optional) trim dataset to include only 2011-2019 and four weight classes: featherweight, lightweight, welterweight, middleweight\n",
    "5. Create subset dataframe of key variables\n",
    "\n",
    "### Creat Key Variables    \n",
    "- __Winner:__ winner of fight (red or blue corner)\n",
    "- __Win red:__ binary, 1 for red win, 0 for red loss\n",
    "- __Experience score:__ interaction between total fights and total rounds fought\n",
    "- __Streak score:__ interaction between current and longest win streak\n",
    "- __Win %:__ total wins divided by total fights\n",
    "- __Finish %:__ percentage of fights that end in KO/TKO, submission, or doctor's stoppage\n",
    "- __Decision %:__ percentage of fights that end in judges' decision\n",
    "- __Offense score:__ interaction between % significant strikes landed, submission attempts, takedowns landed, and knockdowns\n",
    "- __Defense score:__ interaction between % significant strikes absorbed, submission attempts against, and opponent takedowns landed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new variables\n",
    "# r = red corner\n",
    "# b = blue corner\n",
    "\n",
    "# win %\n",
    "df_clean['r_win_pct'] = df_clean.r_wins  / (df_clean.r_wins + df_clean.r_losses + df_clean.r_draw)\n",
    "df_clean['b_win_pct'] = df_clean.b_wins / (df_clean.b_wins + df_clean.b_losses + df_clean.b_draw) \n",
    "\n",
    "# total fights\n",
    "df_clean['r_total_fights'] = df_clean.r_wins + df_clean.r_losses + df_clean.r_draw\n",
    "df_clean['b_total_fights'] = df_clean.b_wins + df_clean.b_losses + df_clean.b_draw \n",
    "\n",
    "# % fights finished by ko/tko, submission, or doctor stoppage\n",
    "df_clean['r_finish_pct'] = (df_clean['r_win_by_ko/tko'] + df_clean.r_win_by_submission +\n",
    "                            df_clean.r_win_by_tko_doctor_stoppage) / df_clean.r_total_fights\n",
    "df_clean['b_finish_pct'] = (df_clean['b_win_by_ko/tko'] + df_clean.b_win_by_submission +\n",
    "                            df_clean.b_win_by_tko_doctor_stoppage) / df_clean.b_total_fights\n",
    "\n",
    "# % fights ended in decision\n",
    "df_clean['r_decision_pct'] = (df_clean.r_win_by_decision_majority + df_clean.r_win_by_decision_split +\n",
    "                              df_clean.r_win_by_decision_unanimous) / df_clean.r_total_fights\n",
    "df_clean['b_decision_pct'] = (df_clean.b_win_by_decision_majority + df_clean.b_win_by_decision_split +\n",
    "                              df_clean.b_win_by_decision_unanimous) / df_clean.b_total_fights\n",
    "\n",
    "# % total strikes landed \n",
    "df_clean['r_total_str_pct'] = df_clean.r_avg_total_str_landed / df_clean.r_avg_total_str_att\n",
    "df_clean['b_total_str_pct'] = df_clean.b_avg_total_str_landed / df_clean.b_avg_total_str_att\n",
    "\n",
    "# average % total strikes absorbed\n",
    "df_clean['r_opp_total_str_pct'] = df_clean.r_avg_opp_total_str_landed / df_clean.r_avg_opp_total_str_att\n",
    "df_clean['b_opp_total_str_pct'] = df_clean.b_avg_opp_total_str_landed / df_clean.b_avg_opp_total_str_att\n",
    "\n",
    "# overall streak score\n",
    "# interaction between current and longest win streak\n",
    "df_clean['r_streak'] = df_clean.r_current_win_streak * df_clean.r_longest_win_streak\n",
    "df_clean['b_streak'] = df_clean.b_current_win_streak * df_clean.b_longest_win_streak\n",
    "\n",
    "# overall offense score\n",
    "# interaction between significant strikes landed,\n",
    "# average knowckdowns, submission attempts, average takedowns landed\n",
    "# divide by 100\n",
    "df_clean['r_offense'] = df_clean.r_avg_sig_str_pct * df_clean.r_avg_kd * df_clean.r_avg_sub_att * df_clean.r_avg_td_pct\n",
    "df_clean['b_offense'] = df_clean.b_avg_sig_str_pct * df_clean.r_avg_kd * df_clean.b_avg_sub_att * df_clean.b_avg_td_pct\n",
    "\n",
    "# overall defense score\n",
    "# interaction between % significant strikes absorbed, \n",
    "# average submission attempts against, and % opponent takedown landed\n",
    "df_clean['r_defense'] = df_clean.r_avg_opp_sig_str_pct * df_clean.r_avg_opp_sub_att * df_clean.r_avg_opp_td_pct\n",
    "df_clean['b_defense'] = df_clean.b_avg_opp_sig_str_pct * df_clean.b_avg_opp_sub_att * df_clean.b_avg_opp_td_pct\n",
    "\n",
    "# overall experience score\n",
    "# interaction between total fights and total rounds fought\n",
    "df_clean['r_experience'] = df_clean.r_total_fights * df_clean.r_total_rounds_fought\n",
    "df_clean['b_experience'] = df_clean.b_total_fights * df_clean.b_total_rounds_fought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse date/time into separate columns\n",
    "df_clean['date'] = pd.to_datetime(df_raw['date'])\n",
    "\n",
    "df_clean['day'] = df_clean.date.dt.day\n",
    "df_clean['month'] = df_clean.date.dt.month\n",
    "df_clean['year'] = df_clean.date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary winner columns \n",
    "df_dum_win = pd.concat([df_clean, pd.get_dummies(df_clean['winner'], prefix='win', dummy_na=True)], axis=1)\n",
    "\n",
    "# combine dummy columns to raw dataset\n",
    "df_clean = pd.concat([df_dum_win, df_raw], axis=1)\n",
    "\n",
    "# convert columns to lowercase\n",
    "df_clean.columns = map(str.lower, df_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate columns\n",
    "df_clean = df_clean.loc[:,~df_clean.columns.duplicated()]\n",
    "\n",
    "# drop nulls\n",
    "df_clean.dropna(axis=0, inplace=True)\n",
    "\n",
    "# ----- OPTIONAL ----- comment or un-comment the code to turn and turn off and run the cell again\n",
    "# drop all rows before 2011 for lack of detailed stats\n",
    "df_clean = df_clean[(df_clean['year'] > 2011) & (df_clean['year'] < 2020)]\n",
    "\n",
    "# ----- OPTIONAL ----- comment or un-comment the code to turn and turn off and run the cell again\n",
    "#drop all weight classes except featherweight(145 lb), lightweight(155 lb),\n",
    "# welterweight(170 lb), and middleweight(185 lb)\n",
    "#df_clean = df_clean.loc[df_clean.weight_class.isin(['Featherweight', 'Lightweight', 'Welterweight', 'Middleweight'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe of key variables and rearrange by similarity groups\n",
    "df_keys = df_clean[['winner',\n",
    "                    'win_red',\n",
    "                    'r_experience',  \n",
    "                    'r_streak',\n",
    "                    'r_win_pct',\n",
    "                    'r_finish_pct',\n",
    "                    'r_decision_pct',\n",
    "                    'r_offense',\n",
    "                    'r_defense',\n",
    "                    'b_experience',\n",
    "                    'b_streak',\n",
    "                    'b_win_pct',\n",
    "                    'b_finish_pct',\n",
    "                    'b_decision_pct',\n",
    "                    'b_offense',\n",
    "                    'b_defense',\n",
    "                    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic size and shape of newly created clean dataframe\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- The new clean dataset contains approximately 200 columns and 3100 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample view of newly created clean dataframe \n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample view of newly created subset of key variables dataframe\n",
    "df_keys.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- The dataset of key variables for modeling has 16 columns and approximately 3300 rows\n",
    "- All feature variables are continuous floats\n",
    "- Target variable option #1: 'winner' as categorical (red or blue)\n",
    "- Target variable option #2: 'win_red' as numerical (1 for red win, 0 for red loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample view of newly created subset of key variables\n",
    "df_keys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "\n",
    "# Exploratory Data Analysis  \n",
    "\n",
    "1. Basic stats\n",
    "2. Bar plot  \n",
    "    > - wins (red vs blue)\n",
    "3. Count plot  \n",
    "    > - weight classes\n",
    "4. Distribution plots  \n",
    "    > - total fights (red vs blue)\n",
    "    > - total wins (red vs blue)\n",
    "    > - age (red vs blue)\n",
    "5. Pair plots   \n",
    "    > - offense and defense (red vs blue) compared to red wins  \n",
    "    > - win % and finish % (red vs blue) compared to red wins  \n",
    "6. Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# basic statistics\n",
    "df_keys.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "- Except for the 'experience' and 'streak' variables, all standard deviations are small. Outliers should be checked for in these two variables.\n",
    "- All of the variables besides 'experience' seem to contain zeros as their minimum. Something does not seem right here. Again, outliers should be investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# bar chart red vs blue total wins\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(df_clean.winner)\n",
    "plt.title('Total Win Count')\n",
    "plt.xlabel('Winner')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# total win count\n",
    "count = df_clean.winner.value_counts()\n",
    "print('Total Win Count')\n",
    "print('')\n",
    "print(count)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "# win %\n",
    "print('Win %')\n",
    "print('')\n",
    "print(count / (count[0] + count[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations  \n",
    "\n",
    "- Out of approximately 3100 total fights, the red corner has won just under 2000 of them, or 64%.\n",
    "- The red corner is historically reserved for the favored, more experienced of the two fighters, so this makes sense.\n",
    "- The above chart is simple but important. Remember our goal is to predict the outcome of a fight. Also remember that the red corner is typically the favored, more experienced fighter. This means that if your only strategy for predicting fights was always choosing the red corner, you would be correct 64% of the time. This number is now our baseline score to beat. If any of the machine learning models score better than 64% accuracy, it could be considered a success. Anything below 64% and the models are worthless because we could always fall back on choosing red every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot of weight classes\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(df_clean.weight_class, order=df_clean.weight_class.value_counts().index)\n",
    "plt.title('Total Fight Count by Weight Class')\n",
    "plt.xlabel('Weight Class')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Fight Count')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print totals\n",
    "print(df_clean.weight_class.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations  \n",
    "- Lightweight (155 lbs) and welterweight (170 lbs) are the most common weight classes and are almost equal in count at approximately 560 each out of 3100 total fights, occuring 36% of the time.\n",
    "- Featherweight (145 lbs) and middleweight (185 lbs) are the next two runnerups and also almost equal each other in count at approximately 375 fights each out of 3100 total fights, occuring 24% of the time.\n",
    "- The featherweight, lightweight, welterweight, and middleweight divisions account for approximately 60% of all fights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distributions comparison\n",
    "\n",
    "# total fights distribution\n",
    "fig, ax = plt.subplots(1, figsize=(8, 4))\n",
    "sns.distplot(df_clean.b_total_fights)\n",
    "sns.distplot(df_clean.r_total_fights)\n",
    "plt.title('Total Fights Distribution')\n",
    "plt.xlabel('# Fights')\n",
    "plt.legend(labels=['Blue','Red'], loc=\"upper right\")\n",
    "\n",
    "# wins distribution\n",
    "fig, ax = plt.subplots(1, figsize=(8, 4))\n",
    "sns.distplot(df_clean.b_wins)\n",
    "sns.distplot(df_clean.r_wins)\n",
    "plt.title('Wins Distribution')\n",
    "plt.xlabel('# Wins')\n",
    "plt.legend(labels=['Blue','Red'], loc=\"upper right\")\n",
    "\n",
    "# age distribution\n",
    "fig, ax = plt.subplots(1, figsize=(8, 4))\n",
    "sns.distplot(df_clean.b_age)\n",
    "sns.distplot(df_clean.r_age)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.legend(labels=['Blue','Red'], loc=\"upper right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# calculate red and blue mean and mode ages\n",
    "r_mean_age = df_clean.r_age.mean()\n",
    "r_mode_age = df_clean.r_age.mode()\n",
    "b_mean_age = df_clean.b_age.mean()\n",
    "b_mode_age = df_clean.b_age.mode()\n",
    "\n",
    "# print red and blue mean ages\n",
    "print('Mean Fighter Age')\n",
    "print('')\n",
    "print('Red: ', (r_mean_age))\n",
    "print('Blue: ', (b_mean_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations  \n",
    "- The red and blue corner distributions have similar shapes to each other in their respective graphs.\n",
    "- There are more blue fighters with < 5 wins than red fighters, and there are more red fighters with > 5 wins than blue fighters. This makes sense, as historically the red corner has been reserved for the favored, more experienced fighter.\n",
    "- The mean age of red and blue are essentially equal at 30 years old. This is surprising. I would have expected the red corner to have a slightly higher mean age since the red corner is typically reserved for the favored, more experienced fighter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot red vs blue offense and defense\n",
    "sns.pairplot(df_keys[['winner',\n",
    "                      'b_offense',\n",
    "                      'r_offense',\n",
    "                      'b_defense',\n",
    "                      'r_defense',\n",
    "                      ]], hue='winner')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot red vs blue win % and finish % compared to red wins\n",
    "sns.pairplot(df_keys[['winner',\n",
    "                      'r_win_pct',\n",
    "                      'b_win_pct',\n",
    "                      'r_finish_pct',\n",
    "                      'b_finish_pct',\n",
    "                      ]], hue='winner')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key variables correlation\n",
    "corr = df_keys.corr()\n",
    "\n",
    "# generate mask for upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# plot heatmap correlation\n",
    "plt.figure(figsize=(25,10))\n",
    "sns.heatmap(corr, mask=mask, annot=True, cbar_kws={\"shrink\": .75}, center=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "- Surprisingly, none of the variables seem to be linearly correlated with the target variable. This does not mean we can rule out non-linear correlation at the moment.\n",
    "- Some variables are correlated with each other. Most notably, 'win %' and 'finish %'. This makes sense since if a fighter has a higher 'finish %' it almost guarantees a relatively high 'win %'. It is probably not common to see a fighter with a high 'win %' and a very low 'finish %'. The UFC greatly values the entertainment factor when putting on shows, not just the caliber of fighters. A fighter with a high win % but always goes to decision typically gets cut from the promotion. It is not enough to win fights; one is also required to be entertaining as well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "# Supervised Learning  \n",
    "1. Define and preprocess data\n",
    "2. Support vector machines\n",
    "3. Naive Bayes\n",
    "4. Logistic regression\n",
    "5. Decision tree/random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import scipy\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from statsmodels.tsa.stattools import acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and preprocess data before modeling\n",
    "\n",
    "# target variable and feature set\n",
    "Y = df_keys.win_red\n",
    "X = df_keys[['r_experience',  \n",
    "             'r_win_pct',\n",
    "             'r_finish_pct',\n",
    "             'r_offense',\n",
    "             'r_defense',\n",
    "             'b_experience',\n",
    "             'b_win_pct',\n",
    "             'b_finish_pct',\n",
    "             'b_offense',\n",
    "             'b_defense'\n",
    "             ]]\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=123)\n",
    "\n",
    "# define standard scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# fit standard scaler\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Support Vector Machines  \n",
    "- Common algorithm for predicting a categorical outcome, which is our goal\n",
    "- Good at finding solutions if variables are non-linearly separable, which is possible with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Observations: 2484\n",
      "Test Set Observations:  622\n",
      "\n",
      "\n",
      "Support Vector Machine Accuracy Score\n",
      "\n",
      "Train Set:  0.643719806763285\n",
      "Test Set:  0.6784565916398714\n"
     ]
    }
   ],
   "source": [
    "# support vector machines\n",
    "\n",
    "# fit model\n",
    "model = svm.SVC()\n",
    "results = model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_preds = results.predict(X_test)\n",
    "\n",
    "# print results\n",
    "print('Train Set Observations: {}'.format(X_train.shape[0]))\n",
    "print('Test Set Observations:  {}'.format(X_test.shape[0]))\n",
    "print('')\n",
    "print('')\n",
    "print('Support Vector Machine Accuracy Score')\n",
    "print('')\n",
    "print('Train Set: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test Set: ', accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- Train and test set are similar at approximately 64% and 68%, which indicates the model is not overfitting.\n",
    "- Not a particularly high accuracy score, but so far it performs better than the baseline strategy of always choosing the red corner to win (64% accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Naive Bayes\n",
    "- Common  classification algorithm for predicting a categorical outcome, which is our goal\n",
    "- Assumes independent variables, probably not the case with this dataset\n",
    "- Curiosity without high hopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes\n",
    "\n",
    "# fit to model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# print results\n",
    "print('Naive Bayes Accuracy Score')\n",
    "print('')\n",
    "print('Train Set: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test Set: ', accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- Train and test set accuracy scores are similar, but 43% is a terrible score. You could achieve far better results by simply choosing the red corner to win every fight (64% accuracy).\n",
    "- Naive Bayes may not be the best option here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Logistic Regression  \n",
    "- Common algorithm for predicting a categorical outcome, which is our goal\n",
    "- Good at predicting the probability of binary outcomes, which is our goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "\n",
    "# fit model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Logistic Regression Accuracy Score')\n",
    "print('')\n",
    "print('Train Set: ', accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Test Set: ', accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- Test set accuracy increased by 5% over the train set. \n",
    "- Logistic regression and support vector machine have performed the best so far at 68%, beating our baseline score of 64% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Decision Tree and Random Forest\n",
    "- Common algorithm for predicting a categorical outcome, which is our goal\n",
    "- Good at learning non-linear relationships, which our dataset could potentially possess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "tree_model = DecisionTreeClassifier()\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit models\n",
    "tree_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# print results\n",
    "print('Decision Tree Accuracy Score')\n",
    "print('')\n",
    "print('Train Set: ', accuracy_score(y_train, tree_model.predict(X_train)))\n",
    "print('Test Set: ', accuracy_score(y_test, tree_model.predict(X_test)))\n",
    "print('')\n",
    "print('')\n",
    "print('Random Forest Accuracy Score')\n",
    "print('')\n",
    "print('Train Set: ', accuracy_score(y_train, rf_model.predict(X_train)))\n",
    "print('Test Set: ', accuracy_score(y_test, rf_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- Accuracy for both decision tree and random forest train set were very high at 99% and 98%, respectively. This suggests the model could be overfitting. It performs well on the known training data, but severely underperforms on the new test set.\n",
    "- Accuracy for both test sets fell dramatically to 57% and 56%. \n",
    "- The train and test sets could possibly have different distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Conclusion  \n",
    "\n",
    "After loading the two original datasets, we discovered that there were some distinct variables in each, and we needed some from both. After joining the datasets, duplicate variables were dropped, which left a clean new set to work with. New variables were then created and combined. Finally, a subset dataframe of key variables was created for modeling. \n",
    "\n",
    "Next came exploratory data analysis. We found out that the red corner wins on average 64% of the time. We chose this as our baseline prediction score to beat. Some other interesting facts arose throughout this phase of the process:  \n",
    "- Total fight count is dominated by just four weight classes: featherweight (145 lbs), lightweight (155 lbs), welterweight (170 lbs), and middleweight (185 lbs), and account for 60% of all fights.\n",
    "- Mean fighter age is 30 years old, which was a bit surprising to learn. Most people think of fighting as a young man's game. This result appears to refute that statement.\n",
    "- No single variable was found to be highly linearly correlated with the target variable. This was very surprising to find out. Professional fighting is a volatile sport. If red consistently wins greater than 50% there should presumably be some combination of features that puts them at a 64% win rate.\n",
    "\n",
    "Our goal of this project was to predict the outcome of UFC fights using supervised learning. Four models were used: support vector machines, naive Bayes, logistic regression, and decision tree/random forest. Both naive Bayes and decision tree/random forest scored terribly and far below the baseline-to-beat of 64% accuracy. Support vector machines and logistic regression scored roughly equal to 64% on their train sets but scored on the test set with 68% accuracy. \n",
    "\n",
    "A score of 68% beats our initial baseline accuracy score of 64%. A small success but a success nonetheless. I believe this score could be improved by implementing the following strategy:\n",
    "1. Address and correct outliers\n",
    "2. Further refining or combining of features with a focus on win/finish %, height/reach advantage, and fighting style (striker, wrestler)\n",
    "3. Identifying the \"typical\" fighter profile in more detail. So far we know it is a male approximately 30 years old who fights in one of the four main weight classes. \n",
    "4. Deeper exploratory data analysis to discover not-so-obvious correlations and connections between variables\n",
    "5. Further model parameter tuning and experimenting with new models \n",
    "\n",
    "Professional fighting is an extremely volatile sport. Even a champion on a winning streak can lose from a split second minor mistake. Fighters commonly perform injured, severely impairing their potential while highlighting their opponent who may not warrant it. Even with unlimited amounts of data, it is entirely possible that predicting fights is a fool's errand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgments\n",
    "- Rajeev Warrier and his Kaggle dataset (https://www.kaggle.com/rajeevw/ufcdata)\n",
    "- Shubhabrata Roy (Thinkful mentor)\n",
    "- Any of you who let me know about an error or typo in any of the above (for real, it would be appreciated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
