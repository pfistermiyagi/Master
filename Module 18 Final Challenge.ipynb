{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to revisit your classifier from the previous assignment. Using the evaluation techniques we've covered here, look at your classifier's performance in more detail. Then go back and iterate by engineering new features, removing poor features, or tuning parameters. Repeat this process until you have five different versions of your classifier. Once you've iterated, answer these questions to compare the performance of each:\n",
    "\n",
    "Do any of your classifiers seem to overfit?\n",
    "Which seem to perform the best? Why?\n",
    "Which features seemed to be most impactful to performance?\n",
    "\n",
    "Write up your iterations and answers to the above questions in a few pages. Submit a link below and go over it with your mentor to see if they have any other ideas on how you could improve your classifier's performance.\n",
    "\n",
    "Estimated time: 1 hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My time: 11111-11\n",
    "\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yelp dataset\n",
    "df = pd.read_csv(r'C:\\Users\\AP\\Desktop\\yelp_clean.csv')\n",
    "\n",
    "# rename columns\n",
    "df.columns = ['review', 'sentiment']\n",
    "\n",
    "# import positive and negative keywords dataset\n",
    "# source: http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "df_neg = pd.read_csv(r'C:\\Users\\AP\\Desktop\\negative words.csv')\n",
    "df_pos = pd.read_csv(r'C:\\Users\\AP\\Desktop\\positive words.csv')\n",
    "\n",
    "# resize data\n",
    "df_neg = df_neg.iloc[35:]\n",
    "df_pos = df_pos.iloc[35:]\n",
    "\n",
    "# drop unnecessary columns\n",
    "df_neg.drop(['Column2', 'Column3', 'Column4', 'Column5'], axis=1, inplace=True)\n",
    "df_pos.drop(['Column2', 'Column3', 'Column4', 'Column5'], axis=1, inplace=True)\n",
    "\n",
    "# convert words in columns to list\n",
    "list_neg = list(df_neg['Column1'])\n",
    "list_pos = list(df_pos['Column1'])\n",
    "\n",
    "# remove non-letter characters from lists\n",
    "import re\n",
    "\n",
    "list_pos = [re.sub('[^A-Za-z0-9]+', '', mystring) for mystring in list_pos]\n",
    "list_pos = list(set(list_pos))\n",
    "\n",
    "list_neg = [re.sub('[^A-Za-z0-9]+', '', mystring) for mystring in list_neg]\n",
    "list_neg = list(set(list_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn sentiment column to boolean\n",
    "df['sentiment'] = (df['sentiment'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 254\n",
      "----------------------------------------------------------------------------------------------------\n",
      "With 20% Holdout: 0.685\n",
      "Testing on Sample: 0.746\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.68 , 0.69 , 0.68 , 0.695, 0.68 ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match keyword list to reviews\n",
    "keywords = list_neg + list_pos\n",
    "\n",
    "for key in keywords:\n",
    "    # add spaces around key so we're getting the word, not just pattern matching\n",
    "    df[str(key)] = df.review.str.contains(' ' + str(key) + ' ',case=False)\n",
    "\n",
    "# define variables for bernoulli classifier\n",
    "data = df[keywords]\n",
    "target = df['sentiment']\n",
    "\n",
    "# import bernoulli classifier (data is binary/boolean)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# instantiate model and store in new variable\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# fit model to data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# classify, store result in new variable\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# display results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0], (target != y_pred).sum()))\n",
    "\n",
    "# section break\n",
    "print(100*'-')\n",
    "\n",
    "# test model with different holdout groups\n",
    "# use train_test_split to create necessary training/test groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "\n",
    "# section break\n",
    "print(100*'-')\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(bnb, data, target, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entire positive and negative keyword lists, this classifier can predict a positive or negative review with 74.6% accuracy. This number seems low, and I bet we can adjust the lists to achieve a higher accuracy score. Cross validation with cv=5 produces consistent results, implying the model is not overfitting.\n",
    "\n",
    "---------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING FOR FOUR ADDITIONAL CLASSIFIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature #2 - positive words only, full list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 278\n",
      "----------------------------------------------------------------------------------------------------\n",
      "With 20% Holdout: 0.675\n",
      "Testing on Sample: 0.722\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.67 , 0.675, 0.665, 0.72 , 0.675])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match keyword list to reviews\n",
    "keywords = list_pos\n",
    "\n",
    "for key in keywords:\n",
    "    # add spaces around key so we're getting the word, not just pattern matching\n",
    "    df[str(key)] = df.review.str.contains(' ' + str(key) + ' ',case=False)\n",
    "    \n",
    "# import bernoulli classifier (data is binary/boolean)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# define variables for bernoulli classifier\n",
    "data = df[keywords]\n",
    "target = df['sentiment']\n",
    "\n",
    "# instantiate model and store in new variable\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# fit model to data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# classify, store result in new variable\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# display results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0], (target != y_pred).sum()))\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "# test model with different holdout groups\n",
    "# use train_test_split to create necessary training/test groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(bnb, data, target, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time only the entire positive keyword list was used in the model. The negative keyword list was left out. Using positive words only, the model can predict sentiment with 72% accuracy. This is slighter lower than using both positive and negative keywords, but overall similar. Cross validation was consistent, yet slightly wider spread than the previous model. Let's try negative keywords only next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------------\n",
    "\n",
    "Feature #3 - negative words only, full list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 347\n",
      "----------------------------------------------------------------------------------------------------\n",
      "With 20% Holdout: 0.585\n",
      "Testing on Sample: 0.653\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6  , 0.575, 0.585, 0.595, 0.57 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match keyword list to reviews\n",
    "keywords = list_neg\n",
    "\n",
    "for key in keywords:\n",
    "    # add spaces around key so we're getting the word, not just pattern matching\n",
    "    df[str(key)] = df.review.str.contains(' ' + str(key) + ' ',case=False)\n",
    "    \n",
    "# import bernoulli classifier (data is binary/boolean)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# define variables for bernoulli classifier\n",
    "data = df[keywords]\n",
    "target = df['sentiment']\n",
    "\n",
    "# instantiate model and store in new variable\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# fit model to data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# classify, store result in new variable\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# display results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0], (target != y_pred).sum()))\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "# test model with different holdout groups\n",
    "# use train_test_split to create necessary training/test groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(bnb, data, target, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the worst performing model so far. Using negative words only to identify sentiment produces an accuracy rate of 65%. Cross validation is consistent like the previous two models, so none of the features seem to be overfitting. \n",
    "\n",
    "The fact that the model can predict sentiment in yelp reviews with a significantly higher accuracy rate using only positive keywords as opposed to negative only words, leads me to believe that overall people leave more positive reviews than negative reviews. This evidence does not prove this theory, but it does fall in line with it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------------\n",
    "\n",
    "Feature #4 - keyword count (multiple keywords in review) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with sentiment column dropped\n",
    "df_1 = df.drop(['sentiment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['matches'] = df_1.eq(True).dot(df_1.columns+',').str[:-1].str.split(',')\n",
    "df['num_matches'] = df['matches'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      2\n",
       "4      1\n",
       "5      2\n",
       "6      1\n",
       "7      2\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     1\n",
       "13     1\n",
       "14     2\n",
       "15     1\n",
       "16     1\n",
       "17     2\n",
       "18     1\n",
       "19     1\n",
       "20     1\n",
       "21     1\n",
       "22     1\n",
       "23     1\n",
       "24     1\n",
       "25     1\n",
       "26     1\n",
       "27     2\n",
       "28     2\n",
       "29     1\n",
       "      ..\n",
       "970    1\n",
       "971    1\n",
       "972    1\n",
       "973    1\n",
       "974    1\n",
       "975    1\n",
       "976    2\n",
       "977    1\n",
       "978    1\n",
       "979    1\n",
       "980    1\n",
       "981    1\n",
       "982    1\n",
       "983    1\n",
       "984    1\n",
       "985    3\n",
       "986    1\n",
       "987    1\n",
       "988    1\n",
       "989    1\n",
       "990    1\n",
       "991    1\n",
       "992    1\n",
       "993    1\n",
       "994    1\n",
       "995    1\n",
       "996    1\n",
       "997    1\n",
       "998    1\n",
       "999    3\n",
       "Name: num_matches, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword count/list in each review, not counting first review column name\n",
    "df['hits'] = df_1.iloc[:, 1:].apply(lambda x: x.index[x.astype(bool)].tolist(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f8c7f57f2d95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hits'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^A-Za-z0-9]+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmystring\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmystring\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#list_pos = list(set(list_pos))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-f8c7f57f2d95>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hits'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[^A-Za-z0-9]+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmystring\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmystring\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#list_pos = list(set(list_pos))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ap\\appdata\\local\\programs\\python\\python37-32\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "df['hits'] = [re.sub('[^A-Za-z0-9]+', '', mystring) for mystring in df['hits']]\n",
    "#list_pos = list(set(list_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review          0\n",
       "smudged         0\n",
       "dissidents      0\n",
       "shallow         0\n",
       "nebulous        0\n",
       "unhelpful       0\n",
       "dislike         0\n",
       "devoid          0\n",
       "chore           0\n",
       "complained      0\n",
       "distraction     0\n",
       "anarchy         0\n",
       "disapointed     0\n",
       "fictional       0\n",
       "gruff           0\n",
       "imprudence      0\n",
       "lament          0\n",
       "complication    0\n",
       "rife            0\n",
       "tricked         0\n",
       "emptiness       0\n",
       "unaccustomed    0\n",
       "intimidating    0\n",
       "underpowered    0\n",
       "futilely        0\n",
       "unnerve         0\n",
       "disorient       0\n",
       "brazen          0\n",
       "fatuously       0\n",
       "profane         0\n",
       "               ..\n",
       "gems            0\n",
       "reputable       0\n",
       "attentive       3\n",
       "titillate       0\n",
       "wholesome       0\n",
       "promising       0\n",
       "versatility     0\n",
       "sincerity       0\n",
       "nourishment     0\n",
       "swanky          0\n",
       "affectionate    0\n",
       "excels          0\n",
       "enrapt          0\n",
       "luxuriously     0\n",
       "windfall        0\n",
       "restructured    0\n",
       "praise          0\n",
       "notably         0\n",
       "bliss           0\n",
       "idolized        0\n",
       "reforming       0\n",
       "replaceable     0\n",
       "succes          0\n",
       "supporter       0\n",
       "aver            0\n",
       "liberate        0\n",
       "convenience     0\n",
       "satisfying      2\n",
       "triumphantly    0\n",
       "topnotch        0\n",
       "Length: 6755, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_1 == 1).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match keyword list to reviews\n",
    "keywords = \n",
    "\n",
    "for key in keywords:\n",
    "    # add spaces around key so we're getting the word, not just pattern matching\n",
    "    df[str(key)] = df.review.str.contains(' ' + str(key) + ' ',case=False)\n",
    "    \n",
    "# import bernoulli classifier (data is binary/boolean)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# define variables for bernoulli classifier\n",
    "data = df[keywords]\n",
    "target = df['sentiment']\n",
    "\n",
    "# instantiate model and store in new variable\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# fit model to data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# classify, store result in new variable\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# display results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0], (target != y_pred).sum()))\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "# test model with different holdout groups\n",
    "# use train_test_split to create necessary training/test groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------------\n",
    "\n",
    "Feature #5 - positive/negative keyword ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match keyword list to reviews\n",
    "keywords = \n",
    "\n",
    "for key in keywords:\n",
    "    # add spaces around key so we're getting the word, not just pattern matching\n",
    "    df[str(key)] = df.review.str.contains(' ' + str(key) + ' ',case=False)\n",
    "    \n",
    "# import bernoulli classifier (data is binary/boolean)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# define variables for bernoulli classifier\n",
    "data = df[keywords]\n",
    "target = df['sentiment']\n",
    "\n",
    "# instantiate model and store in new variable\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# fit model to data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# classify, store result in new variable\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# display results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0], (target != y_pred).sum()))\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "# test model with different holdout groups\n",
    "# use train_test_split to create necessary training/test groups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))\n",
    "\n",
    "print(100*'-')\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
